В процессе спринта был реализован stg слой, в который из источников была загрузка данных as is.

### Шаг 0 - Проверка готовности шаблонов.
Раз я пишу коммента значит репо скопировал с шаблонами, но что важнее необходимая задача это проверить что
stg слой заполняется корректно в postgres и топике Kafka,
доказывая тем самым, что сервис, написанный в спринте, работает корректно.
Данные есть в каждом из вышеприведенных стоков, а сервис стабильно работает.

### Шаг 1 - Создание второго сервиса: распланировать работу над сервисом.
Так как второй сервис это dds слой потока данных, то именно этот этап будет самым объемным по количеству тасков.
Так как для каждой таблицы в dds схеме свой запрос будет реализован. И основная сложность этого шага в количестве
требуемых скриптов и впринципе реализации сервиса без инструкций. Также необходимо спроектировать стоки для Kafka
где будут лежать данные для витрин слоя CDM. Буду описывать все по ходу реализации

### Шаг 2 - Создание второго сервиса: написать код сервиса.
1) Необходимо доработать файлы dds_message_processor_job.py, app.py, app_config.py и добавить новый файл .env с
переменными, в app необходимо прописать процесс с вызовом из файла dds_message_processor_job: class DdsMessageProcessor.
Для начала реализуем сразу выборку данных "только заказы": object_type=='order' и отфильтровонная выборка
будет поступать в продьюсер dds-service-orders, в том же формате и структуре.
2) После теста работы чтения и записи в топик через docker контейнер, необходимо реализовать запись данных в postgres.
Во все якоря, линки и сателиты.
Путем создания функий в классе для записи данных в postgres с соблюдением ограничений написал все и протестировал собрав
контейнер Docker. Тестировал каждый раз при помощи запуска контейнера и в логах отлавливал ошибки, а дальше фиксил в коде.

### Шаг 3 - Создание второго сервиса: зарелизить сервис в Kubernetes.
1) Так как я тестировал сервис с помощью контейнера, то это выполнено на эта разработки.
2)Возникла ошибка связанная с путем до докерфайла, которая не фиксится даже указананием абсолютного пути до директории
сервиса.

docker build . -t cr.yandex/crpc7dibg7j7hj6pa0qa/dds_service:v2024-05-23-r1
[+] Building 0.1s (2/2) FINISHED                                                                         docker:default
 => [internal] load build definition from Dockerfile                                                               0.0s
 => => transferring dockerfile: 2B                                                                                 0.0s
 => [internal] load .dockerignore                                                                                  0.0s
 => => transferring context: 2B                                                                                    0.0s
ERROR: failed to solve: failed to read dockerfile: open /var/lib/docker/tmp/buildkit-mount3733700167/Dockerfile: no such file or directory

Повторил все операции, что делал в спринте по инструкции / заданиям. Результат не изменился, почему-то не видит Dockerfile.
Пробавл изменить права доступа, тоже не помогло.
Собрать, запушить и выполнить релиз не получается по этой причине.
------UPD: Все это было из-за того, что у меня часть скрипта в docker compose была закоменчена (именно часть с сервисом cdm).
Что странно, ведь это 2 сервиса независимых друг от друга и docker compose up у меня получалось делать :/
Запушил образ в registry и разверз в Kubernetes с помощью helm.
Проверил что, появился pod с помощью kubectl.

### Шаг 4 - Создание третьего сервиса: распланировать работу над сервисом.
В CDM — две витрины. Первая витрина — счётчик заказов по блюдам; вторая — счётчик заказов по категориям товаров.
Все это имеет отношение именно к сущности пользователя и агрегация со счетчиком именно по пользователю идет.
Источник здесь также топик кафки dds-service-orders от куда консьюмер будет забирать данные.
Да можно было ранее очистить этот топик еще от не нужной информации, но по факту, сам топик модификаций над данными не
требовал. Поэтому я оставил его таким каким он и был при передаче.
Как реализовать именно счетчики вопрос с подвохом (я ошибся, но где...).
Исходя из того что мы имеем топик который выкидывает конвейером сообщения, то я пришел к выводу что нужно будет считывать
значения по счетчику и обновлять запись. Благо это не hdfs или greenplum (vertica), тут такое так критично не наказывается.

### Шаг 5 - Создание третьего сервиса: написать код сервиса.
Обновим шаблоны, которые были изначально в репе app.py
(добавим аргументов в вызов основного класса для работы с топиком и БД).
cdm_message_processor_job.py (обновим init и начнем прописывать вызов функций для работы с данными считывание + запись.
cdm_repository.py (файл со скриптами для внесения данных в postgres в cdm слой).
Занятная вещь получается со счетчиком по продуктам все в полном порядке, а вот со счетчиком по
категориям вышел недочет самого курса Практикума.  В заданиях спринта указан что у бизнес атрибута "Категория", помимо
имени есть еще и индекс, однако после построения структуры БД и при считывании json из источников становится понятно,
что есть только category_name без category_id.
Только в процессе того как я делал cdm слой я понял что ключи берутся из детального слоя и category_id, product_id, user_id
Это ключи Хэш из таблиц h_* детального слоя.



